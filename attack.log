Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Method of attack: Linf-PGD
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Method of attack: Linf-PGD
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.5, 0.7, 0.7, 0.8, 0.8, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 0.7, 0.7, 0.8, 0.8, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.5, 0.7, 0.7, 0.7, 0.8, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0')]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.5, 0.7, 0.7, 0.7, 0.9, 0.8, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.625, 0.375, 0.375, 0.375, 0.125, 0.25, 0.125, 0.125, 1.25, 1.25, 1.25, 1.25]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.4, 0.6, 0.6, 0.5]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, inf, 27.5, 30.25, 23.38, 33.0, 11.0]
Number of queries used: 60
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.4, 0.8, 0.9]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 34.83, 14.67, 33.0, 36.67, 28.33]
Number of queries used: 60
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.4, 0.4, 0.5, 0.7, 0.9]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, inf, nan, nan, 40.0, 36.67, 37.5, 72.5, 48.0]
Number of queries used: 100
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 0.5, 0.4, 0.5, 0.9]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.625, 0.75, 0.625, 0.125]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 32.5, 20.0, 10.0, 10.0, 12.25]
Number of queries used: 50
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 5
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.625, 0.75, 0.625, 0.125]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.4, 0.6, 0.6, 0.5]
Type two-point-forward variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.625, 0.75, 0.625, 0.125]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.4, 0.8, 0.9]
Type two-point-backward variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.625, 0.75, 0.625, 0.125]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.4, 0.4, 0.5, 0.7, 0.9]
Type two-point-central variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.625, 0.75, 0.625, 0.125]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 0.5, 0.4, 0.5, 0.9]
Type one-point-residual variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.0, 0.75, 0.5, 0.5, 0.625, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.125, 1.25, 0.75, 0.75, 0.625, 0.375, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.625, 0.75, 0.625, 0.125]
test z at epsilon: 0.0
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 0.7, 0.7, 0.7, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 0.4, 0.5, 0.7, 0.8]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, inf, 19.25, 18.33, 15.12, 26.95, 16.87]
Number of queries used: 60
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.4, 0.5, 0.9]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 46.75, 11.0, 11.0, 12.38, 25.85]
Number of queries used: 60
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.3, 0.5, 0.6, 0.8]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 60.0, 25.0, 56.67, 50.0, 40.0]
Number of queries used: 100
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.3, 0.3, 0.7, 0.8]
Variance: [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.875, 0.875, 0.375, 0.25]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 18.33, 17.5, 10.0, 12.0, 30.0]
Number of queries used: 50
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 5
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 0.7, 0.7, 0.7, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.875, 0.875, 0.375, 0.25]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 0.4, 0.5, 0.7, 0.8]
Type two-point-forward variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.875, 0.875, 0.375, 0.25]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.4, 0.5, 0.9]
Type two-point-backward variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.875, 0.875, 0.375, 0.25]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.3, 0.5, 0.6, 0.8]
Type two-point-central variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.875, 0.875, 0.375, 0.25]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.3, 0.3, 0.7, 0.8]
Type one-point-residual variance : [1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.875, 0.5, 0.375, 0.375, 0.375, 0.25, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 0.875, 0.75, 0.625, 0.375, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.75, 0.75, 0.625, 0.125, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.125, 1.25, 1.0, 0.875, 0.625, 0.5, 0.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 1.25, 0.75, 0.875, 0.875, 0.375, 0.25]
test z at epsilon: 0.0
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 0.7, 0.7, 0.8, 0.8, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.5, 0.9]
Variance: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 35.75, 46.75, 16.5, 33.0, 19.25]
Number of queries used: 60
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.3, 0.6, 0.5, 0.9]
Variance: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 66.0, 11.0, 11.0, 27.5, 29.33, 23.1]
Number of queries used: 60
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.3, 0.3, 0.5, 0.6, 0.7]
Variance: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 80.0, 20.0, 35.0, 20.0, 46.67, 50.0, 53.33]
Number of queries used: 100
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.7, 0.6]
Variance: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 10.0, 25.0, 13.75, 21.67, 25.0]
Number of queries used: 50
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 5
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.6, 0.7, 0.7, 0.8, 0.8, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.5, 0.9]
Type two-point-forward variance : [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.3, 0.6, 0.5, 0.9]
Type two-point-backward variance : [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.3, 0.3, 0.5, 0.6, 0.7]
Type two-point-central variance : [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.7, 0.6]
Type one-point-residual variance : [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]
test z at epsilon: 0.0
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 0.7, 0.7, 0.8, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.4, 0.5, 0.7]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 46.75, 14.67, 11.0, 15.12, 16.5]
Number of queries used: 60
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.3, 0.5, 0.5, 0.5, 0.7]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 19.25, 19.25, 31.17, 11.0, 27.04]
Number of queries used: 60
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.4, 0.5, 0.5, 0.7]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 50.0, 30.0, 20.0, 53.33, 20.0]
Number of queries used: 100
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.5, 0.6, 0.8]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 70.0, 20.0, 10.0, 13.75, 13.75, 20.0]
Number of queries used: 50
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 5
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 0.7, 0.7, 0.8, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.4, 0.5, 0.7]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.3, 0.5, 0.5, 0.5, 0.7]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.4, 0.5, 0.5, 0.7]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.5, 0.6, 0.8]
test z at epsilon: 0.0
one-point-residual, white-box z_test: 6.324555320336759, significant: False
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.4, 0.4, 0.4, 0.5]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, inf, 16.5, 16.5, 11.0, 11.0]
Number of queries used: 60
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.6, 0.6, 0.9]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 77.0, 33.0, 16.5, 36.67, 16.5, 22.83]
Number of queries used: 60
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.2, 0.4, 0.4, 0.6, 0.8]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, inf, 36.67, 26.67, 24.0, 20.0]
Number of queries used: 100
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.5, 0.6, 0.7]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 25.0, 10.0, 10.0, 10.0, 21.67]
Number of queries used: 50
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 5
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.4, 0.4, 0.4, 0.5]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.6, 0.6, 0.9]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.2, 0.4, 0.4, 0.6, 0.8]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.5, 0.6, 0.7]
test z at epsilon: 0.0
one-point-residual, white-box z_test: 4.830458915396479, significant: False
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.3, 0.6, 0.9, 0.9]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 22.0, 22.0, 28.05, 25.85]
Number of queries used: 60
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.6, 1.0]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 38.5, 22.0, 16.5, 25.67, 27.5]
Number of queries used: 60
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.5, 0.6, 0.8, 0.7]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 60.0, 35.0, 57.5, 50.0, 74.17]
Number of queries used: 100
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.4, 0.3, 0.8, 0.8]
Average number of queries until succes: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 40.0, 16.67, 10.0, 12.67, 13.0]
Number of queries used: 50
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 5
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.3, 0.6, 0.9, 0.9]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3, 0.6, 1.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.5, 0.6, 0.8, 0.7]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.4, 0.3, 0.8, 0.8]
test z at epsilon: 0.3
one-point-residual, white-box z_test: 6.324555320336759, significant: False
one-point-residual, two-point-forward z_test: 0, significant: True
one-point-residual, two-point-backward z_test: 0, significant: True
one-point-residual, two-point-central z_test: 0, significant: True
one-point-residual, one-point-residual z_test: 0, significant: True
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 5
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 4
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.5, 0.6, 0.6, 0.8, 0.7, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.5, 0.4, 0.6, 0.7]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104]
Average number of queries until succes: [nan, nan, nan, 33.0, 16.5, 17.6, 11.0, 22.0, 15.71]
Number of queries used: 50
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.3, 0.4, 0.4, 0.7]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104]
Average number of queries until succes: [nan, nan, 44.0, nan, 11.0, 11.0, 11.0, 13.75, 12.57]
Number of queries used: 50
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.3, 0.5, 0.6, 0.9]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776]
Average number of queries until succes: [nan, nan, nan, 80.0, 40.0, 20.0, 28.0, 33.33, 28.89]
Number of queries used: 80
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.5, 0.8]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26249998807907104, 0.26249998807907104, 0.3125, 0.3125, 0.20000000298023224]
Average number of queries until succes: [nan, nan, nan, nan, 10.0, 20.0, 24.0, 14.0, 11.25]
Number of queries used: 40
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 4
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.5, 0.6, 0.6, 0.8, 0.7, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26249998807907104, 0.26249998807907104, 0.3125, 0.3125, 0.20000000298023224]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.5, 0.4, 0.6, 0.7]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26249998807907104, 0.26249998807907104, 0.3125, 0.3125, 0.20000000298023224]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.3, 0.4, 0.4, 0.7]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26249998807907104, 0.26249998807907104, 0.3125, 0.3125, 0.20000000298023224]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.3, 0.5, 0.6, 0.9]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26249998807907104, 0.26249998807907104, 0.3125, 0.3125, 0.20000000298023224]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.5, 0.8]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000001788139343, 0.30000001192092896, 0.3125, 0.29999998211860657, 0.29999998211860657, 0.20000000298023224, 0.26249998807907104, 0.20000000298023224, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.20000001788139343, 0.3125, 0.30000001192092896, 0.29999998211860657, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249999701976776, 0.0, 0.20000001788139343, 0.26249998807907104, 0.30000001192092896, 0.30000001192092896, 0.26249998807907104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11249998956918716, 0.11249999701976776, 0.26249998807907104, 0.3125, 0.29999998211860657, 0.11249999701976776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26249998807907104, 0.26249998807907104, 0.3125, 0.3125, 0.20000000298023224]
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 4
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.6, 0.6, 0.7, 0.7, 0.7, 0.8, 0.9, 0.9, 1.0, 1.0, 1.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.2, 0.8, 0.8]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2]
Average number of queries until succes: [nan, nan, nan, nan, 11.0, 24.75, 11.0, 17.88, 13.75]
Number of queries used: 50
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.5, 0.8]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2]
Average number of queries until succes: [nan, nan, nan, nan, 22.0, 11.0, 24.2, 17.6, 16.5]
Number of queries used: 50
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.4, 0.5, 0.8, 0.6]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3]
Average number of queries until succes: [nan, nan, nan, nan, 60.0, 30.0, 36.0, 40.0, 20.0]
Number of queries used: 80
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.4, 0.5, 0.6, 0.7]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.3, 0.262]
Average number of queries until succes: [nan, nan, nan, nan, 40.0, 10.0, 16.0, 10.0, 10.0]
Number of queries used: 40
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 4
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.6, 0.6, 0.7, 0.7, 0.7, 0.8, 0.9, 0.9, 1.0, 1.0, 1.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.3, 0.262]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.4, 0.2, 0.8, 0.8]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.3, 0.262]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.5, 0.5, 0.8]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.3, 0.262]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.4, 0.5, 0.8, 0.6]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.3, 0.262]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.4, 0.5, 0.6, 0.7]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.3, 0.262, 0.262, 0.262, 0.2, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.3, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.262, 0.312, 0.312, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.3, 0.312, 0.3, 0.262]
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 4
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.5, 0.7, 0.7, 0.7, 0.7, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.262, 0.312, 0.262, 0.262, 0.262, 0.262, 0.2, 0.112, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 4
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.6, 0.7, 0.7, 0.7, 0.6, 0.7, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2]
Average number of queries until succes: [nan, nan, nan, 11.0, 27.5, 14.67, 16.5, 22.0, 11.0]
Number of queries used: 50
Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 0.4, 0.6, 0.7, 0.9]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112]
Average number of queries until succes: [nan, nan, nan, 22.0, 18.33, 16.5, 22.0, 11.0, 14.67]
Number of queries used: 50
Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.3, 0.3, 0.4, 0.6, 0.8]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2]
Average number of queries until succes: [nan, nan, 40.0, 60.0, 40.0, 26.67, 20.0, 26.67, 25.0]
Number of queries used: 80
Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.2, 0.3, 0.6, 0.7]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.2, 0.262, 0.3, 0.262]
Average number of queries until succes: [nan, nan, nan, 10.0, 10.0, 10.0, 16.67, 15.0, 10.0]
Number of queries used: 40
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 4
nb_samples: 10
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.4, 0.6, 0.7, 0.7, 0.7, 0.6, 0.7, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.2, 0.262, 0.3, 0.262]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.2, 0.262, 0.3, 0.262]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.3, 0.4, 0.6, 0.7, 0.9]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.2, 0.262, 0.3, 0.262]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.3, 0.3, 0.4, 0.6, 0.8]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.2, 0.262, 0.3, 0.262]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.2, 0.3, 0.6, 0.7]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.3, 0.3, 0.262, 0.262, 0.262, 0.3, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.2, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.262, 0.3, 0.3, 0.262, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.262, 0.262, 0.3, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.112, 0.2, 0.262, 0.3, 0.262]
test z at epsilon: 0.3
one-point-residual, white-box z_test: 4.830458915396479, significant: False
one-point-residual, two-point-forward z_test: 0, significant: True
one-point-residual, two-point-backward z_test: 0, significant: True
one-point-residual, two-point-central z_test: 0, significant: True
one-point-residual, one-point-residual z_test: 0, significant: True
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.60 %
Accuracy attacked model: 99.6
Testing: white-box
Accuracy: [0.01, 0.01, 0.01, 0.016, 0.022, 0.054, 0.324, 0.784, 0.976, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.084, 0.298, 0.688, 0.924, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1053.99, 913.31, 817.02, 635.46, 511.12, 402.9, 292.54, 246.02, 164.93]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.082, 0.296, 0.692, 0.912, 0.992, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1062.42, 914.6, 813.04, 651.37, 516.22, 403.51, 314.36, 225.42, 172.89]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.084, 0.3, 0.708, 0.922, 0.988, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1966.47, 1696.18, 1530.6, 1232.4, 988.0, 784.6, 606.0, 474.2, 355.8]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.054, 0.198, 0.524, 0.802, 0.948, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.051, 0.159, 0.25, 0.159, 0.049, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1334.55, 1198.07, 1047.4, 849.7, 669.1, 522.1, 376.6, 300.8, 213.2]
Number of queries used: 2500
Accuracy attacked model: 99.6
Defense model: net2conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.01, 0.01, 0.01, 0.016, 0.022, 0.054, 0.324, 0.784, 0.976, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.051, 0.159, 0.25, 0.159, 0.049, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.084, 0.298, 0.688, 0.924, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.051, 0.159, 0.25, 0.159, 0.049, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.082, 0.296, 0.692, 0.912, 0.992, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.051, 0.159, 0.25, 0.159, 0.049, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.084, 0.3, 0.708, 0.922, 0.988, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.051, 0.159, 0.25, 0.159, 0.049, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.054, 0.198, 0.524, 0.802, 0.948, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.01, 0.01, 0.01, 0.016, 0.022, 0.051, 0.22, 0.17, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.018, 0.077, 0.21, 0.216, 0.071, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.076, 0.209, 0.214, 0.081, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.012, 0.02, 0.077, 0.211, 0.208, 0.072, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.016, 0.051, 0.159, 0.25, 0.159, 0.049, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 0.3
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 20
loss: tensor(2.3036, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.0433, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7220, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6730, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6378, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4905, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4475, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8121, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6718, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5792, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3154, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 20
loss: tensor(0.5783, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7555, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5308, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4673, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6584, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5433, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4720, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4778, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3112, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4056, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6035, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3417, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 3 / 20
loss: tensor(0.4744, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3737, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3424, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5318, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5563, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3444, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6589, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6318, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3643, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4454, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2784, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4103, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 4 / 20
loss: tensor(0.3788, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5990, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4917, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5673, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3103, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3912, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3691, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4576, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3186, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 5 / 20
loss: tensor(0.3298, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5376, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4534, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4864, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3367, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4107, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4065, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3174, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4090, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2450, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2395, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 6 / 20
loss: tensor(0.2145, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2901, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1884, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3955, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4255, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3093, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4158, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2696, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4993, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3231, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3554, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4449, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 7 / 20
loss: tensor(0.4051, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3617, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3987, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3355, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5375, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2535, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3355, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3461, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2070, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3336, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2335, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2745, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 8 / 20
loss: tensor(0.2512, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3558, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3156, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0931, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3844, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2740, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2808, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5138, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 9 / 20
loss: tensor(0.2961, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3790, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2034, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3287, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2365, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3618, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6008, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4682, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3977, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 10 / 20
loss: tensor(0.2533, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2154, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4483, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2164, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4414, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3769, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6213, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5158, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2188, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2345, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3895, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 11 / 20
loss: tensor(0.3132, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3296, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4065, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3338, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3003, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2347, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2774, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3240, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3137, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2767, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4305, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 12 / 20
loss: tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1759, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2926, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2314, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2849, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2881, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2234, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3777, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1925, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3536, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3527, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 13 / 20
loss: tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2763, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2093, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3820, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1760, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2939, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1835, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2235, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3039, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2236, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 14 / 20
loss: tensor(0.1877, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5985, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3588, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2891, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3739, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3906, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2938, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2966, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2718, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4176, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1331, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 15 / 20
loss: tensor(0.2426, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1349, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1547, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2405, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4853, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4662, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3466, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3669, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1886, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1771, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 16 / 20
loss: tensor(0.4321, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4676, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2850, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1949, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2650, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2319, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2892, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2842, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1745, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 17 / 20
loss: tensor(0.1238, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3546, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3211, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2064, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1726, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1587, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1350, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2961, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2016, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3391, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 18 / 20
loss: tensor(0.4173, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1241, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1874, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4302, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2233, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2425, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1303, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1714, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1584, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 19 / 20
loss: tensor(0.1236, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2007, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3003, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2196, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2178, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2550, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1635, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1115, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1526, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 20 / 20
loss: tensor(0.1794, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1949, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1951, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1230, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2503, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0856, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2093, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3336, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1948, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 90.85 %
Accuracy attacked model: 90.85
Testing: white-box
Accuracy: [0.07, 0.086, 0.13, 0.244, 0.394, 0.64, 0.92, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.065, 0.079, 0.114, 0.185, 0.24, 0.231, 0.074, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.048, 0.052, 0.06, 0.088, 0.108, 0.224, 0.64, 0.858, 0.948, 0.988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.046, 0.049, 0.057, 0.081, 0.097, 0.175, 0.231, 0.122, 0.049, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [498.98, 436.97, 380.77, 308.65, 233.89, 195.43, 161.06, 138.52, 113.32]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.048, 0.054, 0.062, 0.084, 0.108, 0.216, 0.646, 0.868, 0.946, 0.988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.046, 0.051, 0.058, 0.077, 0.097, 0.17, 0.23, 0.115, 0.051, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [492.56, 426.77, 383.11, 313.55, 246.43, 202.67, 166.57, 138.52, 128.01]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.05, 0.056, 0.064, 0.1, 0.142, 0.274, 0.718, 0.898, 0.958, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.048, 0.053, 0.06, 0.09, 0.122, 0.2, 0.203, 0.092, 0.04, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [817.8, 727.6, 639.6, 554.8, 439.2, 367.4, 309.0, 242.0, 214.2]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.048, 0.054, 0.06, 0.078, 0.11, 0.192, 0.616, 0.842, 0.926, 0.972, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.046, 0.051, 0.057, 0.072, 0.098, 0.156, 0.237, 0.134, 0.069, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [575.9, 512.2, 451.4, 361.2, 281.1, 247.8, 185.2, 155.9, 123.0]
Number of queries used: 2500
Accuracy attacked model: 90.85
Defense model: net2conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.07, 0.086, 0.13, 0.244, 0.394, 0.64, 0.92, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [[0.065, 0.079, 0.114, 0.185, 0.24, 0.231, 0.074, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.049, 0.057, 0.081, 0.097, 0.175, 0.231, 0.122, 0.049, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.058, 0.077, 0.097, 0.17, 0.23, 0.115, 0.051, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048, 0.053, 0.06, 0.09, 0.122, 0.2, 0.203, 0.092, 0.04, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.057, 0.072, 0.098, 0.156, 0.237, 0.134, 0.069, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
Type two-point-forward accuracy : [0.048, 0.052, 0.06, 0.088, 0.108, 0.224, 0.64, 0.858, 0.948, 0.988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [[0.065, 0.079, 0.114, 0.185, 0.24, 0.231, 0.074, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.049, 0.057, 0.081, 0.097, 0.175, 0.231, 0.122, 0.049, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.058, 0.077, 0.097, 0.17, 0.23, 0.115, 0.051, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048, 0.053, 0.06, 0.09, 0.122, 0.2, 0.203, 0.092, 0.04, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.057, 0.072, 0.098, 0.156, 0.237, 0.134, 0.069, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
Type two-point-backward accuracy : [0.048, 0.054, 0.062, 0.084, 0.108, 0.216, 0.646, 0.868, 0.946, 0.988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [[0.065, 0.079, 0.114, 0.185, 0.24, 0.231, 0.074, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.049, 0.057, 0.081, 0.097, 0.175, 0.231, 0.122, 0.049, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.058, 0.077, 0.097, 0.17, 0.23, 0.115, 0.051, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048, 0.053, 0.06, 0.09, 0.122, 0.2, 0.203, 0.092, 0.04, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.057, 0.072, 0.098, 0.156, 0.237, 0.134, 0.069, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
Type two-point-central accuracy : [0.05, 0.056, 0.064, 0.1, 0.142, 0.274, 0.718, 0.898, 0.958, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [[0.065, 0.079, 0.114, 0.185, 0.24, 0.231, 0.074, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.049, 0.057, 0.081, 0.097, 0.175, 0.231, 0.122, 0.049, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.058, 0.077, 0.097, 0.17, 0.23, 0.115, 0.051, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048, 0.053, 0.06, 0.09, 0.122, 0.2, 0.203, 0.092, 0.04, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.057, 0.072, 0.098, 0.156, 0.237, 0.134, 0.069, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
Type one-point-residual accuracy : [0.048, 0.054, 0.06, 0.078, 0.11, 0.192, 0.616, 0.842, 0.926, 0.972, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [[0.065, 0.079, 0.114, 0.185, 0.24, 0.231, 0.074, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.049, 0.057, 0.081, 0.097, 0.175, 0.231, 0.122, 0.049, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.058, 0.077, 0.097, 0.17, 0.23, 0.115, 0.051, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048, 0.053, 0.06, 0.09, 0.122, 0.2, 0.203, 0.092, 0.04, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046, 0.051, 0.057, 0.072, 0.098, 0.156, 0.237, 0.134, 0.069, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
test z at epsilon: 0.3
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 3
Starting training the victim net V
epoch: 1 / 20
loss: tensor(2.3038, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.1522, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.0731, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7767, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8090, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6309, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5264, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5737, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7036, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5886, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2967, device='cuda:0', grad_fn=<NllLossBackward>)
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 3
Loading 'defense' is done.
Accuracy of netV: 90.85 %
Accuracy attacked model: 90.85
Testing: white-box
Accuracy: [0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0]
Variance: [0.262, 0.262, 0.262, 0.262, 0.3, 0.312, 0.262, 0.2, 0.2, 0.2, 0.2, 0.2, 0.112, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.3, 0.5, 0.6, 0.7, 0.8, 0.8]
Variance: [0.2, 0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.3, 0.3, 0.262, 0.312, 0.3, 0.262, 0.2, 0.2]
Average number of queries until succes: [8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0]
Number of queries used: 20
Testing: two-point-backward
Accuracy: [0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.2, 0.5, 0.4, 0.3, 0.5, 0.4, 0.6, 0.8, 0.7, 0.9]
Variance: [0.2, 0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.2, 0.312, 0.3, 0.262, 0.312, 0.3, 0.3, 0.2, 0.262, 0.112]
Average number of queries until succes: [8.4, 6.0, 6.0, 8.4, 6.0, 6.0, 6.0, 6.0, 6.0]
Number of queries used: 20
Testing: two-point-central
Accuracy: [0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.3, 0.3, 0.5, 0.6, 0.8, 0.8, 0.8, 0.9]
Variance: [0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.3, 0.3, 0.262, 0.262, 0.312, 0.3, 0.2, 0.2, 0.2, 0.112]
Average number of queries until succes: [10.0, 10.0, 10.0, 12.0, 10.0, 10.0, 10.0, 10.0, 10.0]
Number of queries used: 30
Testing: one-point-residual
Accuracy: [0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.2, 0.4, 0.6, 0.7, 0.8, 0.7, 0.7]
Variance: [0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.2, 0.3, 0.3, 0.262, 0.2, 0.262, 0.262]
Average number of queries until succes: [5.0, 6.67, 10.0, 5.0, 5.0, 5.71, 5.62, 5.0, 5.0]
Number of queries used: 15
Accuracy attacked model: 90.85
Defense model: net2conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 3
nb_samples: 5
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.262, 0.262, 0.262, 0.262, 0.3, 0.312, 0.262, 0.2, 0.2, 0.2, 0.2, 0.2, 0.112, 0.112, 0.112, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.3, 0.5, 0.6, 0.7, 0.8, 0.8]
Type two-point-forward variance : [0.2, 0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.3, 0.3, 0.262, 0.312, 0.3, 0.262, 0.2, 0.2]
Type two-point-backward accuracy : [0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.2, 0.5, 0.4, 0.3, 0.5, 0.4, 0.6, 0.8, 0.7, 0.9]
Type two-point-backward variance : [0.2, 0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.2, 0.312, 0.3, 0.262, 0.312, 0.3, 0.3, 0.2, 0.262, 0.112]
Type two-point-central accuracy : [0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.3, 0.3, 0.5, 0.6, 0.8, 0.8, 0.8, 0.9]
Type two-point-central variance : [0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.3, 0.3, 0.262, 0.262, 0.312, 0.3, 0.2, 0.2, 0.2, 0.112]
Type one-point-residual accuracy : [0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.2, 0.4, 0.6, 0.7, 0.8, 0.7, 0.7]
Type one-point-residual variance : [0.2, 0.2, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.262, 0.2, 0.3, 0.3, 0.262, 0.2, 0.262, 0.262]
test z at epsilon: 0.3
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.85 %
Accuracy attacked model: 90.85
Testing: white-box
Accuracy: [0.068, 0.414, 0.77, 0.908, 0.978, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.064, 0.244, 0.178, 0.084, 0.022, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.06, 0.226, 0.514, 0.756, 0.88, 0.954, 0.988, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.057, 0.176, 0.251, 0.185, 0.106, 0.044, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1548.74, 1211.48, 940.85, 707.27, 578.95, 434.93, 342.01]
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.06, 0.226, 0.522, 0.758, 0.884, 0.948, 0.988, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.057, 0.176, 0.251, 0.184, 0.103, 0.049, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1564.48, 1210.35, 926.26, 711.25, 558.55, 455.74, 356.8]
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.062, 0.27, 0.622, 0.816, 0.918, 0.972, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.058, 0.198, 0.236, 0.151, 0.076, 0.027, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [2472.37, 1892.6, 1486.0, 1178.0, 946.4, 744.2, 590.4]
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.06, 0.232, 0.528, 0.752, 0.874, 0.934, 0.976, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.057, 0.179, 0.25, 0.187, 0.111, 0.062, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1668.86, 1386.7, 1079.7, 838.0, 680.1, 519.0, 418.4]
Number of queries used: 5000
Accuracy attacked model: 90.85
Defense model: net2conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.068, 0.414, 0.77, 0.908, 0.978, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.064, 0.244, 0.178, 0.084, 0.022, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.06, 0.226, 0.514, 0.756, 0.88, 0.954, 0.988, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.057, 0.176, 0.251, 0.185, 0.106, 0.044, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.06, 0.226, 0.522, 0.758, 0.884, 0.948, 0.988, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.057, 0.176, 0.251, 0.184, 0.103, 0.049, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.062, 0.27, 0.622, 0.816, 0.918, 0.972, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.058, 0.198, 0.236, 0.151, 0.076, 0.027, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.06, 0.232, 0.528, 0.752, 0.874, 0.934, 0.976, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.057, 0.179, 0.25, 0.187, 0.111, 0.062, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 1.066481825835005, significant: True
one-point-residual, two-point-forward z_test: 0.34538821901650557, significant: True
one-point-residual, two-point-backward z_test: 0.24297910931126313, significant: True
one-point-residual, two-point-central z_test: 0.6466109454139582, significant: True
one-point-residual, one-point-residual z_test: 0.0, significant: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.3], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.3], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [2.5], eps_iters: [0.125], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.968]
Variance: [0.031]
Average number of queries until succes: []
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [2.5], eps_iters: [0.125], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.972]
Variance: [0.027]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.846]
Variance: [0.131]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Testing pgd attack with estimates
epsilons: [2.5], eps_iters: [0.125], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [2.5], eps_iters: [0.125], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [2.5], eps_iters: [0.125], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.964]
Variance: [0.035]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.846]
Variance: [0.131]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.842]
Variance: [0.134]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.866]
Variance: [0.117]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.71]
Variance: [0.207]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.5]
eps_iter: [0.125]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.964]
Type white-box variance : [0.035]
Type two-point-forward accuracy : [0.846]
Type two-point-forward variance : [0.131]
Type two-point-backward accuracy : [0.842]
Type two-point-backward variance : [0.134]
Type two-point-central accuracy : [0.866]
Type two-point-central variance : [0.117]
Type one-point-residual accuracy : [0.71]
Type one-point-residual variance : [0.207]
Testing pgd attack with estimates
epsilons: [2.5], eps_iters: [0.125], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [0.0]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.928]
Variance: [0.067]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.944]
Variance: [0.053]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.966]
Variance: [0.033]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Testing pgd attack with estimates
epsilons: [0.3], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [-0.0]
Average number of queries until succes: [0.0]
Testing: two-point-forward
Accuracy: [1.0]
Variance: [-0.0]
Average number of queries until succes: [459.0]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [-0.0]
Average number of queries until succes: [510.0]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [-0.0]
Average number of queries until succes: [700.0]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [-0.0]
Average number of queries until succes: [650.0]
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.3]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [-0.0]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [-0.0]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [-0.0]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [-0.0]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [-0.0]
Testing pgd attack with estimates
epsilons: [0.3], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: [0.0]
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: [663.0]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: [663.0]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: [1000.0]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: [825.0]
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.3]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.2]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.1], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.1]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.5]
Type two-point-forward variance : [inf]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.5]
Type two-point-central variance : [inf]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.15], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Testing pgd attack with estimates
epsilons: [0.15], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.15]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.5]
Type two-point-backward variance : [inf]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.15], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.15]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.15], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.15]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.5]
Type one-point-residual variance : [inf]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.25]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.25], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.2]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.5]
Type two-point-forward variance : [inf]
Type two-point-backward accuracy : [0.5]
Type two-point-backward variance : [inf]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.5]
Type two-point-forward variance : [inf]
Type two-point-backward accuracy : [0.5]
Type two-point-backward variance : [inf]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.5]
Type two-point-forward variance : [inf]
Type two-point-backward accuracy : [0.5]
Type two-point-backward variance : [inf]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.5]
Variance: [inf]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.5]
Type two-point-forward variance : [inf]
Type two-point-backward accuracy : [0.5]
Type two-point-backward variance : [inf]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.2]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [1.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [1.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [1.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [1.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.2], eps_iters: [0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.2]
eps_iter: [0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [2.0], eps_iters: [0.1], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [1.0]
Variance: [nan]
Average number of queries until succes: []
Testing: two-point-forward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.0]
Variance: [nan]
Average number of queries until succes: []
Number of queries used: 5000
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [2.0]
eps_iter: [0.1]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [1.0]
Type white-box variance : [nan]
Type two-point-forward accuracy : [0.0]
Type two-point-forward variance : [nan]
Type two-point-backward accuracy : [0.0]
Type two-point-backward variance : [nan]
Type two-point-central accuracy : [0.0]
Type two-point-central variance : [nan]
Type one-point-residual accuracy : [0.0]
Type one-point-residual variance : [nan]
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 50
loss: tensor(2.3098, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.1516, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.0269, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8601, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7513, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8989, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6934, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7435, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6267, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7566, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7257, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5213, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 50
loss: tensor(0.6950, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4865, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5874, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5326, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6567, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6787, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6818, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5077, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4168, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7554, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6275, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6030, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 3 / 50
loss: tensor(0.4493, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4860, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4374, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4220, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3709, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6274, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5617, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5167, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3781, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 4 / 50
loss: tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3519, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4416, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3861, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3297, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4964, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4708, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4154, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4583, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4435, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4863, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 5 / 50
loss: tensor(0.5379, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2374, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5180, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4640, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4824, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2863, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3586, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2848, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4026, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2793, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4733, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4300, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 6 / 50
loss: tensor(0.4100, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5410, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3914, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2755, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3505, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5479, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3957, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2725, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5991, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3510, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2229, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 7 / 50
loss: tensor(0.5409, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2362, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3788, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3584, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4483, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3138, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4269, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3331, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2062, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1674, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 8 / 50
loss: tensor(0.3489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2799, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3134, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3349, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5582, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3182, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3798, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3294, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4260, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3988, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 9 / 50
loss: tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5373, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2443, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2732, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2716, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3776, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2526, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3570, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4573, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3672, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 10 / 50
loss: tensor(0.4456, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3100, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3560, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3554, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3678, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3309, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3251, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2562, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3565, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2993, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 11 / 50
loss: tensor(0.3344, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2387, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1689, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3396, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2906, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7568, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3010, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3331, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5309, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2835, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2709, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 12 / 50
loss: tensor(0.1008, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2628, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2694, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2868, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3038, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3902, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1980, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3566, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4330, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4391, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 13 / 50
loss: tensor(0.3545, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2549, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4165, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4711, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2670, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3360, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2904, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2278, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4733, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 14 / 50
loss: tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3238, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2098, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4415, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4355, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2161, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1441, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5376, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2023, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1398, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 15 / 50
loss: tensor(0.3686, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2029, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3213, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1923, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3736, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2979, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2377, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3283, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2480, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1779, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 16 / 50
loss: tensor(0.2328, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3728, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2439, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2780, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1763, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3646, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2906, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2039, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2172, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 17 / 50
loss: tensor(0.2619, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3466, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2664, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2058, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4744, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3461, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4285, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3754, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2463, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 18 / 50
loss: tensor(0.3777, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2447, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4546, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2652, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3008, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3227, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2416, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2234, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 19 / 50
loss: tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2434, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1649, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1454, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1623, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2855, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4198, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2087, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2877, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2499, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2159, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 20 / 50
loss: tensor(0.2885, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2988, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3979, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1352, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5796, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2524, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2826, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1722, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3093, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2764, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 21 / 50
loss: tensor(0.2316, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2906, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2512, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2273, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2553, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3514, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2285, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1993, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2380, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1372, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 22 / 50
loss: tensor(0.1831, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1859, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2404, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2050, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1119, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2130, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2071, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2113, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 23 / 50
loss: tensor(0.3016, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4314, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2335, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2120, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1605, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2728, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2243, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2340, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4174, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 24 / 50
loss: tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1055, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3021, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2550, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2384, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1871, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 25 / 50
loss: tensor(0.2050, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2276, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3869, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2609, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2433, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2208, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3009, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2441, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1990, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 26 / 50
loss: tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2227, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2429, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1397, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2490, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3124, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3785, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1968, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 27 / 50
loss: tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2976, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1445, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0764, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3616, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1114, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 28 / 50
loss: tensor(0.4043, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3153, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2178, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2282, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1524, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2122, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3772, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1994, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3261, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 29 / 50
loss: tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1328, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1746, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1411, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1734, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2070, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1936, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2391, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2353, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2861, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 30 / 50
loss: tensor(0.2655, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1781, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2619, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1641, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2346, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1008, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2154, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3064, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 31 / 50
loss: tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1631, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2547, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1746, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2484, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2326, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1756, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 32 / 50
loss: tensor(0.2651, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3684, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2767, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1334, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1608, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0989, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1571, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 33 / 50
loss: tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0829, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1495, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2954, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2205, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0918, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1634, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2811, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 34 / 50
loss: tensor(0.1257, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1350, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1113, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1457, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1354, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3246, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2046, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2779, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2347, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 35 / 50
loss: tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1603, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1949, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2071, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2564, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2257, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1361, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 36 / 50
loss: tensor(0.2043, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2257, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1207, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1552, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2142, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1957, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1568, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2986, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2593, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1459, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 37 / 50
loss: tensor(0.1495, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2795, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1607, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1465, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4164, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1796, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2817, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2345, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 38 / 50
loss: tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1097, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0944, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2248, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1599, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2839, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1776, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 39 / 50
loss: tensor(0.2947, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0922, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1787, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1210, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2415, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1965, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1615, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1231, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 40 / 50
loss: tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0594, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1725, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3548, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1628, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1613, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1214, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1185, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 41 / 50
loss: tensor(0.1766, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2659, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3072, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1025, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1604, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1236, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2647, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3092, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1395, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0781, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2120, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 42 / 50
loss: tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1618, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2334, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1293, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1909, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1772, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2539, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 43 / 50
loss: tensor(0.1730, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2637, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0935, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1516, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1423, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1917, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2241, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 44 / 50
loss: tensor(0.3007, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2054, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1322, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2263, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2019, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1449, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 45 / 50
loss: tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0679, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2820, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1009, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2425, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1213, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1749, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 46 / 50
loss: tensor(0.1352, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1874, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2285, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1860, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1361, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1090, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0868, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0767, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 47 / 50
loss: tensor(0.1063, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2953, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0748, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0631, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1156, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1201, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2058, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 48 / 50
loss: tensor(0.1148, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1820, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2023, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1063, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 49 / 50
loss: tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1041, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1378, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1424, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2343, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 50 / 50
loss: tensor(0.1772, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2039, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1838, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0935, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0895, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1984, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1715, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 91.20 %
Accuracy attacked model: 91.2
Testing: white-box
Accuracy: [0.086, 0.688, 0.938, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.079, 0.216, 0.058, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forwardTesting pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 20
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 20
loss: tensor(2.2984, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.4664, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8638, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7752, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8684, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7374, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7962, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8978, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.0542, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7285, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8553, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6429, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 20
loss: tensor(0.6757, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6484, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4632, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5887, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4537, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5526, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5032, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8199, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7057, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3998, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5321, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6075, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 3 / 20
loss: tensor(0.7910, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5769, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8131, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6322, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6787, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4683, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5873, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5615, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4294, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3651, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 4 / 20
loss: tensor(0.5270, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3981, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5092, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6272, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6712, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5793, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4257, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5024, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5460, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4325, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 5 / 20
loss: tensor(0.5190, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3529, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4467, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5338, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3987, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4324, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3739, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5109, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4175, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2841, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5121, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 6 / 20
loss: tensor(0.3592, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6348, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3692, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4092, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4636, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6714, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4048, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4814, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2446, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4186, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4705, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2651, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 7 / 20
loss: tensor(0.4100, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3821, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5734, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3663, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5842, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7261, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3458, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3310, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3421, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3834, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4168, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 8 / 20
loss: tensor(0.3421, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4322, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2440, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6865, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3696, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2015, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2698, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2505, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3840, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5067, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6505, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4015, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 9 / 20
loss: tensor(0.2453, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2833, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3729, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2980, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3272, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4490, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5203, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3172, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4398, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3803, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5465, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 10 / 20
loss: tensor(0.4003, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2476, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3640, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3948, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3626, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3837, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2570, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4055, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4339, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2476, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4841, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 11 / 20
loss: tensor(0.3457, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3920, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5085, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3915, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5357, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3888, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3271, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2291, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3642, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3901, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 12 / 20
loss: tensor(0.4219, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3492, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4454, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3597, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4400, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4090, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4920, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4959, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2311, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3870, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4390, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2486, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 13 / 20
loss: tensor(0.2706, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4317, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4622, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3391, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2731, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2753, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3658, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3310, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4956, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5354, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 14 / 20
loss: tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4250, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1313, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4364, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3666, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3232, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4322, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3112, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2485, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3902, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 15 / 20
loss: tensor(0.3319, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5218, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2991, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2876, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3201, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3420, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3233, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2211, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3460, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3281, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2274, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4979, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 16 / 20
loss: tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3533, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2519, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3357, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2696, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4382, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1898, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3279, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1804, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3562, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2502, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 17 / 20
loss: tensor(0.3503, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3306, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2684, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2971, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2873, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3123, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2771, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2291, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3949, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 18 / 20
loss: tensor(0.3084, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3150, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1985, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2681, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2550, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2805, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5009, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1755, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1307, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3031, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 19 / 20
loss: tensor(0.3085, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2013, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2778, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1881, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3013, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1364, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2025, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2210, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2732, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2641, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3996, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 20 / 20
loss: tensor(0.2377, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3123, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2841, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3469, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2964, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2463, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2928, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2814, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2394, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2612, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3256, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 89.50 %
Accuracy attacked model: 89.5
Testing: white-box
Accuracy: [0.088, 0.504, 0.852, 0.932, 0.972, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.081, 0.251, 0.127, 0.064, 0.027, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 20
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 50
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 50
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 50
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Starting training the victim net V
epoch: 1 / 50
loss: tensor(2.3034, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.6190, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.9770, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.9801, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8208, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8008, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6657, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.9198, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7809, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8386, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8801, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 50
loss: tensor(0.5795, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7405, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5725, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8222, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5403, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5762, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6135, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5722, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5584, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6905, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5311, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6395, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 3 / 50
loss: tensor(0.5239, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6476, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5733, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5078, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6492, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7100, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5123, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5648, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 4 / 50
loss: tensor(0.7059, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3905, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6521, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4043, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6432, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6703, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5293, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7524, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5701, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5444, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2857, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3904, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 5 / 50
loss: tensor(0.5355, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4946, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4024, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3034, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6205, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3525, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5586, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.8100, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4029, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2915, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 6 / 50
loss: tensor(0.3085, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2748, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3452, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4747, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5588, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4390, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4700, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5017, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3589, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4875, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3689, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4327, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 7 / 50
loss: tensor(0.3611, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4352, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3719, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2819, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6117, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3482, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3645, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3568, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4814, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6160, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5456, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6526, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 8 / 50
loss: tensor(0.2957, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3391, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4320, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2873, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6507, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3266, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.7305, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3706, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3561, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3388, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 9 / 50
loss: tensor(0.3988, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2375, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3544, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5616, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4934, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3637, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3517, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3392, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2970, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4021, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 10 / 50
loss: tensor(0.3667, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3367, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3930, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5387, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3473, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3677, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3346, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2316, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3162, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4553, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 11 / 50
loss: tensor(0.3141, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4829, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2189, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3445, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3846, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2761, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2627, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2195, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4000, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2795, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 12 / 50
loss: tensor(0.3936, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4080, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4389, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5675, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3432, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2826, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2484, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1944, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5798, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2996, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3149, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 13 / 50
loss: tensor(0.3854, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2600, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3540, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3364, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2313, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2726, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4368, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3469, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1627, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2987, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2492, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 14 / 50
loss: tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4746, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3273, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3399, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2438, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2949, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2544, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2955, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3327, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1886, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1617, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 15 / 50
loss: tensor(0.2310, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3445, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2720, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2921, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1495, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2866, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4179, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4779, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4300, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3397, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3804, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 16 / 50
loss: tensor(0.3356, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2782, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3792, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4266, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1538, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2897, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2059, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2704, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1834, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4480, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3493, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 17 / 50
loss: tensor(0.4076, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2571, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1996, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3030, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2924, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2712, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3985, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3844, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3068, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2630, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 18 / 50
loss: tensor(0.2196, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5025, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1908, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3995, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3654, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1930, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2186, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4074, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2921, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 19 / 50
loss: tensor(0.2784, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2719, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2836, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2032, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3433, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1853, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4474, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4182, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1904, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2668, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 20 / 50
loss: tensor(0.2616, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1609, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2760, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2692, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1924, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3076, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2402, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3181, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2047, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2746, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2950, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 21 / 50
loss: tensor(0.2558, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1210, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1705, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4592, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2521, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2442, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3556, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1820, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2913, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3517, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2037, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 22 / 50
loss: tensor(0.2899, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2480, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3138, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2438, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2899, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3400, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2527, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2386, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1722, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2557, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4031, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3111, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 23 / 50
loss: tensor(0.2244, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2752, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4038, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3782, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3915, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2523, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2600, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2035, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1964, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 24 / 50
loss: tensor(0.3383, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2824, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2910, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1454, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1470, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3336, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2713, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3938, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2161, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2156, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 25 / 50
loss: tensor(0.2514, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2382, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3885, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2310, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2796, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2847, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1835, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1337, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3262, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3115, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 26 / 50
loss: tensor(0.1439, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1869, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1491, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2288, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1570, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1210, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2280, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2906, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0817, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 27 / 50
loss: tensor(0.1904, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1833, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2389, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2016, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1459, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3165, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1572, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2819, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3619, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 28 / 50
loss: tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1917, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2209, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1354, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2497, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1700, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2007, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 29 / 50
loss: tensor(0.0717, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2251, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1604, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1919, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3107, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4701, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1857, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2809, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1174, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4066, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 30 / 50
loss: tensor(0.3071, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2653, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2512, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2050, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0569, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3898, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1704, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2447, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1598, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 31 / 50
loss: tensor(0.1881, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1204, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1869, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2661, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2931, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2032, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3289, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3247, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4785, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 32 / 50
loss: tensor(0.2768, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2158, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1893, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2274, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2839, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2570, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3701, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2546, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3525, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2550, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 33 / 50
loss: tensor(0.0745, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2410, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2617, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1714, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2211, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1626, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2537, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1630, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2136, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3021, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 34 / 50
loss: tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1422, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2195, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1108, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1649, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2210, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1178, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1943, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2190, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1390, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 35 / 50
loss: tensor(0.1524, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2737, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1911, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1652, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1941, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1671, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1479, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 36 / 50
loss: tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1667, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4590, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1956, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1766, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1405, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2214, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0780, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 37 / 50
loss: tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3838, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1590, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1236, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2432, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1201, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1578, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3263, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1859, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 38 / 50
loss: tensor(0.2369, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2305, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1328, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1450, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1391, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1048, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1639, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3538, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0813, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2407, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1988, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2526, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 39 / 50
loss: tensor(0.2928, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1549, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1784, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1718, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1139, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2083, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1615, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2018, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1457, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 40 / 50
loss: tensor(0.2360, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1880, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1474, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1347, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1748, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1046, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1935, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1269, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 41 / 50
loss: tensor(0.1601, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1891, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3294, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1708, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1405, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2287, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1986, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0857, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0733, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 42 / 50
loss: tensor(0.1359, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2025, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1883, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1474, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1122, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4679, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 43 / 50
loss: tensor(0.2101, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1321, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2830, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1364, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1419, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2879, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2380, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 44 / 50
loss: tensor(0.0824, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2255, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2504, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1439, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1509, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2469, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0910, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0950, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1396, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0714, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 45 / 50
loss: tensor(0.1633, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1218, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0984, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1770, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1877, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1550, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1767, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3106, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 46 / 50
loss: tensor(0.1631, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1456, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1676, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0931, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0905, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3027, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1301, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0705, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 47 / 50
loss: tensor(0.1263, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1095, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1908, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1954, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2047, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0658, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3664, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0578, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 48 / 50
loss: tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1981, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0681, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2924, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2440, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2404, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1223, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0797, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 49 / 50
loss: tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1263, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1442, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2168, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1400, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1173, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1641, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1116, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 50 / 50
loss: tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1991, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2506, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2169, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1048, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1087, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1418, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1215, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 91.50 %
Accuracy attacked model: 91.5
Testing: white-box
Accuracy: [0.07, 0.784, 0.97, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.065, 0.17, 0.029, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 91.50 %
Accuracy attacked model: 91.5
Testing: white-box
Accuracy: [0.084, 0.116, 0.234, 0.528, 0.728, 0.924, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.077, 0.103, 0.18, 0.25, 0.199, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.042, 0.044, 0.062, 0.108, 0.182, 0.478, 0.846, 0.98, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.04, 0.042, 0.058, 0.097, 0.149, 0.251, 0.131, 0.02, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [193.49, 169.73, 147.08, 121.69, 101.29, 91.8, 86.09, 76.6, 76.81]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.04, 0.048, 0.058, 0.104, 0.174, 0.482, 0.856, 0.982, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.039, 0.046, 0.055, 0.094, 0.144, 0.251, 0.124, 0.018, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [196.15, 177.17, 152.49, 125.26, 105.77, 97.1, 83.95, 80.07, 75.79]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.042, 0.048, 0.068, 0.128, 0.236, 0.572, 0.932, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.04, 0.046, 0.064, 0.112, 0.181, 0.246, 0.064, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [313.8, 294.2, 267.2, 221.0, 177.6, 173.2, 147.0, 152.4, 143.8]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.042, 0.044, 0.056, 0.094, 0.154, 0.428, 0.88, 0.976, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.04, 0.042, 0.053, 0.086, 0.131, 0.246, 0.106, 0.024, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [204.0, 186.0, 159.3, 136.7, 119.7, 102.6, 86.6, 83.9, 79.5]
Number of queries used: 2500
Accuracy attacked model: 91.5
Defense model: net4conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.084, 0.116, 0.234, 0.528, 0.728, 0.924, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.077, 0.103, 0.18, 0.25, 0.199, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.042, 0.044, 0.062, 0.108, 0.182, 0.478, 0.846, 0.98, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.04, 0.042, 0.058, 0.097, 0.149, 0.251, 0.131, 0.02, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.04, 0.048, 0.058, 0.104, 0.174, 0.482, 0.856, 0.982, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.039, 0.046, 0.055, 0.094, 0.144, 0.251, 0.124, 0.018, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.042, 0.048, 0.068, 0.128, 0.236, 0.572, 0.932, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.04, 0.046, 0.064, 0.112, 0.181, 0.246, 0.064, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.042, 0.044, 0.056, 0.094, 0.154, 0.428, 0.88, 0.976, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.04, 0.042, 0.053, 0.086, 0.131, 0.246, 0.106, 0.024, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 0.3
one-point-residual, white-box z_test: 0.0, H_0 rejected: False
one-point-residual, two-point-forward z_test: 0.0, H_0 rejected: False
one-point-residual, two-point-backward z_test: 0.0, H_0 rejected: False
one-point-residual, two-point-central z_test: 0.0, H_0 rejected: False
one-point-residual, one-point-residual z_test: 0.0, H_0 rejected: False
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 10
loss: tensor(2.3024, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.4133, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4422, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4119, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3637, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5590, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2452, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1530, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1373, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2437, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1457, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 10
loss: tensor(0.1179, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2230, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2786, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0824, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0828, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0634, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 3 / 10
loss: tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0796, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1853, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0970, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1430, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1999, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 4 / 10
loss: tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2343, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 5 / 10
loss: tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4876, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2083, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1456, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 6 / 10
loss: tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1477, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 7 / 10
loss: tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2534, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0844, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1750, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 8 / 10
loss: tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1239, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1285, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0557, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 9 / 10
loss: tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0265, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 10 / 10
loss: tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 99.40 %
Accuracy attacked model: 99.4
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 5
loss: tensor(2.2983, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.5716, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.6868, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5468, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4917, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4913, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1101, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1596, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1641, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2652, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3423, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 5
loss: tensor(0.2624, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1519, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1103, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1448, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1594, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1550, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0774, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 3 / 5
loss: tensor(0.0465, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1714, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1699, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1382, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1934, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 4 / 5
loss: tensor(0.0768, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0639, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1489, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1725, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0604, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1312, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0425, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 5 / 5
loss: tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3048, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 99.15 %
Accuracy attacked model: 99.15
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 2
loss: tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.3286, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3060, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.5351, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2094, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3641, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3370, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2439, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2134, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2797, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1880, device='cuda:0', grad_fn=<NllLossBackward>)
epoch: 2 / 2
loss: tensor(0.3003, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1093, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.3205, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0501, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1622, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.1595, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward>)
Finished training of netV
Loading 'defense' is done.
Accuracy of netV: 98.10 %
Accuracy attacked model: 98.1
Testing: white-box
Accuracy: [0.024, 0.026, 0.028, 0.044, 0.06, 0.114, 0.29, 0.71, 0.918, 0.982, 0.996, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.024, 0.025, 0.027, 0.042, 0.057, 0.101, 0.207, 0.207, 0.076, 0.018, 0.004, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.024, 0.024, 0.024, 0.026, 0.036, 0.052, 0.148, 0.306, 0.658, 0.846, 0.946, 0.98, 0.988, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.024, 0.024, 0.024, 0.025, 0.035, 0.049, 0.127, 0.213, 0.226, 0.131, 0.051, 0.02, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1012.19, 879.18, 773.57, 606.06, 478.18, 363.94, 290.7, 231.74, 187.99]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.024, 0.024, 0.026, 0.026, 0.032, 0.052, 0.144, 0.304, 0.65, 0.838, 0.95, 0.98, 0.988, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.024, 0.024, 0.025, 0.025, 0.031, 0.049, 0.124, 0.212, 0.228, 0.136, 0.048, 0.02, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1000.91, 873.56, 758.6, 609.3, 479.2, 379.54, 294.27, 224.4, 195.02]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.024, 0.024, 0.026, 0.026, 0.034, 0.052, 0.158, 0.34, 0.68, 0.854, 0.95, 0.978, 0.992, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.024, 0.024, 0.025, 0.025, 0.033, 0.049, 0.134, 0.225, 0.218, 0.125, 0.048, 0.022, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1799.26, 1610.38, 1450.2, 1168.23, 905.8, 732.0, 558.2, 420.8, 380.6]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.024, 0.024, 0.024, 0.026, 0.028, 0.044, 0.124, 0.262, 0.592, 0.782, 0.902, 0.95, 0.976, 0.994, 0.998, 1.0, 1.0, 1.0, 1.0]
Variance: [0.024, 0.024, 0.024, 0.025, 0.027, 0.042, 0.109, 0.194, 0.243, 0.171, 0.089, 0.048, 0.024, 0.006, 0.002, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1148.96, 1052.23, 947.16, 760.34, 611.11, 451.9, 349.8, 281.4, 238.3]
Number of queries used: 2500
Accuracy attacked model: 98.1
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.024, 0.026, 0.028, 0.044, 0.06, 0.114, 0.29, 0.71, 0.918, 0.982, 0.996, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.024, 0.025, 0.027, 0.042, 0.057, 0.101, 0.207, 0.207, 0.076, 0.018, 0.004, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.024, 0.024, 0.024, 0.026, 0.036, 0.052, 0.148, 0.306, 0.658, 0.846, 0.946, 0.98, 0.988, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.024, 0.024, 0.024, 0.025, 0.035, 0.049, 0.127, 0.213, 0.226, 0.131, 0.051, 0.02, 0.012, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.024, 0.024, 0.026, 0.026, 0.032, 0.052, 0.144, 0.304, 0.65, 0.838, 0.95, 0.98, 0.988, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.024, 0.024, 0.025, 0.025, 0.031, 0.049, 0.124, 0.212, 0.228, 0.136, 0.048, 0.02, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.024, 0.024, 0.026, 0.026, 0.034, 0.052, 0.158, 0.34, 0.68, 0.854, 0.95, 0.978, 0.992, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.024, 0.024, 0.025, 0.025, 0.033, 0.049, 0.134, 0.225, 0.218, 0.125, 0.048, 0.022, 0.008, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.024, 0.024, 0.024, 0.026, 0.028, 0.044, 0.124, 0.262, 0.592, 0.782, 0.902, 0.95, 0.976, 0.994, 0.998, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.024, 0.024, 0.024, 0.025, 0.027, 0.042, 0.109, 0.194, 0.243, 0.171, 0.089, 0.048, 0.024, 0.006, 0.002, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 0.3
one-point-residual, white-box z_test: 1.61, H_0 rejected: False
one-point-residual, two-point-forward z_test: 0.786, H_0 rejected: False
one-point-residual, two-point-backward z_test: 0.854, H_0 rejected: False
one-point-residual, two-point-central z_test: 0.854, H_0 rejected: False
one-point-residual, one-point-residual z_test: 0.0, H_0 rejected: False
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 2
loss: tensor(2.3025, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward>)
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 2
loss: tensor(2.3002, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.3092, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.4662, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(0.2821, device='cuda:0', grad_fn=<NllLossBackward>)
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 2
loss: tensor(2.3038, device='cuda:0', grad_fn=<NllLossBackward>)
loss: tensor(1.6464, device='cuda:0', grad_fn=<NllLossBackward>)
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Starting training the victim net V
epoch: 1 / 2
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.01, 0.01, 0.012, 0.018, 0.034, 0.056, 0.253, 0.691, 0.947, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.012, 0.018, 0.033, 0.053, 0.19, 0.214, 0.051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.013, 0.022, 0.075, 0.253, 0.573, 0.878, 0.975, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.01, 0.013, 0.022, 0.07, 0.19, 0.245, 0.108, 0.025, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1149.297, 1021.723, 900.387, 735.863, 595.103, 456.317, 340.983, 259.933, 183.667]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.013, 0.024, 0.073, 0.252, 0.575, 0.878, 0.971, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.01, 0.013, 0.024, 0.068, 0.189, 0.245, 0.108, 0.029, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1142.76, 1016.027, 901.68, 728.893, 578.85, 468.283, 359.277, 255.95, 190.263]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.013, 0.025, 0.078, 0.253, 0.584, 0.895, 0.976, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.01, 0.013, 0.025, 0.072, 0.19, 0.244, 0.094, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [2166.867, 1930.4, 1701.2, 1390.333, 1127.0, 898.4, 673.333, 511.467, 366.4]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.01, 0.01, 0.01, 0.01, 0.011, 0.019, 0.062, 0.172, 0.44, 0.755, 0.925, 0.98, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.01, 0.01, 0.01, 0.011, 0.019, 0.058, 0.143, 0.247, 0.186, 0.07, 0.02, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1451.03, 1308.277, 1166.44, 936.6, 749.933, 582.7, 445.1, 320.7, 224.767]
Number of queries used: 2500
Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.01, 0.01, 0.012, 0.018, 0.034, 0.056, 0.253, 0.691, 0.947, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.01, 0.01, 0.012, 0.018, 0.033, 0.053, 0.19, 0.214, 0.051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.01, 0.01, 0.01, 0.01, 0.013, 0.022, 0.075, 0.253, 0.573, 0.878, 0.975, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.01, 0.01, 0.01, 0.01, 0.013, 0.022, 0.07, 0.19, 0.245, 0.108, 0.025, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.01, 0.01, 0.01, 0.01, 0.013, 0.024, 0.073, 0.252, 0.575, 0.878, 0.971, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.01, 0.01, 0.01, 0.01, 0.013, 0.024, 0.068, 0.189, 0.245, 0.108, 0.029, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.01, 0.01, 0.01, 0.01, 0.013, 0.025, 0.078, 0.253, 0.584, 0.895, 0.976, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.01, 0.01, 0.01, 0.01, 0.013, 0.025, 0.072, 0.19, 0.244, 0.094, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.01, 0.01, 0.01, 0.01, 0.011, 0.019, 0.062, 0.172, 0.44, 0.755, 0.925, 0.98, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.01, 0.01, 0.01, 0.01, 0.011, 0.019, 0.058, 0.143, 0.247, 0.186, 0.07, 0.02, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 0.25
one-point-residual, white-box z_test: 4.759, H_0 rejected: True
one-point-residual, two-point-forward z_test: 2.705, H_0 rejected: True
one-point-residual, two-point-backward z_test: 2.705, H_0 rejected: True
one-point-residual, two-point-central z_test: 3.023, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0.0, H_0 rejected: False
Testing pgd attack with estimates
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], eps_iters: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025], nb_iter: 50
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.092, 0.096, 0.132, 0.243, 0.414, 0.683, 0.915, 0.989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.084, 0.087, 0.115, 0.184, 0.244, 0.217, 0.078, 0.011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.075, 0.079, 0.087, 0.096, 0.122, 0.213, 0.666, 0.861, 0.932, 0.981, 0.995, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.07, 0.073, 0.08, 0.087, 0.108, 0.168, 0.224, 0.12, 0.064, 0.019, 0.005, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [484.117, 417.317, 371.45, 300.527, 250.24, 208.66, 181.83, 160.513, 135.457]
Number of queries used: 2550
Testing: two-point-backward
Accuracy: [0.075, 0.079, 0.086, 0.095, 0.123, 0.217, 0.67, 0.863, 0.932, 0.983, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.07, 0.073, 0.079, 0.087, 0.109, 0.171, 0.222, 0.119, 0.064, 0.017, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [478.997, 412.523, 376.31, 302.127, 249.22, 215.663, 181.9, 154.973, 132.8]
Number of queries used: 2550
Testing: two-point-central
Accuracy: [0.079, 0.084, 0.09, 0.105, 0.139, 0.267, 0.76, 0.892, 0.952, 0.991, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.073, 0.077, 0.082, 0.095, 0.12, 0.196, 0.183, 0.097, 0.046, 0.009, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [803.943, 704.333, 638.133, 521.667, 471.267, 391.267, 334.0, 293.4, 252.333]
Number of queries used: 5000
Testing: one-point-residual
Accuracy: [0.076, 0.082, 0.087, 0.093, 0.121, 0.197, 0.654, 0.853, 0.915, 0.962, 0.988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.071, 0.076, 0.08, 0.085, 0.107, 0.158, 0.227, 0.126, 0.078, 0.037, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [539.39, 493.067, 444.767, 354.733, 296.0, 249.867, 215.467, 173.0, 156.533]
Number of queries used: 2500
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: Linf-PGD
epsilons: [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
eps_iter: [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]
nb_iter: 50
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.092, 0.096, 0.132, 0.243, 0.414, 0.683, 0.915, 0.989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.084, 0.087, 0.115, 0.184, 0.244, 0.217, 0.078, 0.011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.075, 0.079, 0.087, 0.096, 0.122, 0.213, 0.666, 0.861, 0.932, 0.981, 0.995, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.07, 0.073, 0.08, 0.087, 0.108, 0.168, 0.224, 0.12, 0.064, 0.019, 0.005, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.075, 0.079, 0.086, 0.095, 0.123, 0.217, 0.67, 0.863, 0.932, 0.983, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.07, 0.073, 0.079, 0.087, 0.109, 0.171, 0.222, 0.119, 0.064, 0.017, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.079, 0.084, 0.09, 0.105, 0.139, 0.267, 0.76, 0.892, 0.952, 0.991, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.073, 0.077, 0.082, 0.095, 0.12, 0.196, 0.183, 0.097, 0.046, 0.009, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.076, 0.082, 0.087, 0.093, 0.121, 0.197, 0.654, 0.853, 0.915, 0.962, 0.988, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.071, 0.076, 0.08, 0.085, 0.107, 0.158, 0.227, 0.126, 0.078, 0.037, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 0.25
one-point-residual, white-box z_test: 0.618, H_0 rejected: False
one-point-residual, two-point-forward z_test: 0.314, H_0 rejected: False
one-point-residual, two-point-backward z_test: 0.346, H_0 rejected: False
one-point-residual, two-point-central z_test: 0.475, H_0 rejected: False
one-point-residual, one-point-residual z_test: 0.0, H_0 rejected: False
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.092, 0.432, 0.789, 0.904, 0.973, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.084, 0.246, 0.167, 0.087, 0.026, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.088, 0.233, 0.553, 0.765, 0.867, 0.937, 0.979, 0.997, 0.999, 1.0, 1.0, 1.0, 1.0]
Variance: [0.081, 0.179, 0.248, 0.181, 0.116, 0.059, 0.021, 0.003, 0.001, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1265.71, 994.533, 750.247, 596.09, 478.31, 386.953, 320.52]
Number of queries used: 5050
Testing: two-point-backward
Accuracy: [0.088, 0.234, 0.545, 0.771, 0.869, 0.934, 0.98, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.081, 0.18, 0.249, 0.178, 0.115, 0.062, 0.02, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1293.29, 997.837, 761.053, 598.467, 475.42, 390.153, 321.603]
Number of queries used: 5050
Testing: two-point-central
Accuracy: [0.09, 0.311, 0.672, 0.84, 0.913, 0.967, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.082, 0.215, 0.221, 0.135, 0.08, 0.032, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [2047.93, 1586.267, 1238.267, 996.933, 819.533, 684.133, 570.2]
Number of queries used: 10000
Testing: one-point-residual
Accuracy: [0.086, 0.231, 0.571, 0.78, 0.863, 0.919, 0.972, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.079, 0.179, 0.246, 0.172, 0.119, 0.075, 0.027, 0.005, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [1372.947, 1122.477, 886.867, 710.867, 578.233, 467.867, 393.1]
Number of queries used: 5000
Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.092, 0.432, 0.789, 0.904, 0.973, 0.999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.084, 0.246, 0.167, 0.087, 0.026, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.088, 0.233, 0.553, 0.765, 0.867, 0.937, 0.979, 0.997, 0.999, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.081, 0.179, 0.248, 0.181, 0.116, 0.059, 0.021, 0.003, 0.001, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.088, 0.234, 0.545, 0.771, 0.869, 0.934, 0.98, 0.996, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.081, 0.18, 0.249, 0.178, 0.115, 0.062, 0.02, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.09, 0.311, 0.672, 0.84, 0.913, 0.967, 0.992, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.082, 0.215, 0.221, 0.135, 0.08, 0.032, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.086, 0.231, 0.571, 0.78, 0.863, 0.919, 0.972, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.079, 0.179, 0.246, 0.172, 0.119, 0.075, 0.027, 0.005, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 1.348, H_0 rejected: False
one-point-residual, two-point-forward z_test: 0.319, H_0 rejected: False
one-point-residual, two-point-backward z_test: 0.267, H_0 rejected: False
one-point-residual, two-point-central z_test: 0.83, H_0 rejected: False
one-point-residual, one-point-residual z_test: 0.0, H_0 rejected: False
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]
Testing: two-point-forward
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]
Testing: two-point-forward
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]

Testing: two-point-backward
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]

Testing: two-point-central
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]

Testing: one-point-residual
Accuracy: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Variance: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Average number of queries until succes: [0, 0, 0, 0, 0, 0, 0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type white-box variance : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type two-point-forward accuracy : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type two-point-forward variance : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type two-point-backward accuracy : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type two-point-backward variance : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type two-point-central accuracy : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type two-point-central variance : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type one-point-residual accuracy : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type one-point-residual variance : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Type white-box avg_queries_until_success : [0, 0, 0, 0, 0, 0, 0]
Type two-point-forward avg_queries_until_success : [0, 0, 0, 0, 0, 0, 0]
Type two-point-backward avg_queries_until_success : [0, 0, 0, 0, 0, 0, 0]
Type two-point-central avg_queries_until_success : [0, 0, 0, 0, 0, 0, 0]
Type one-point-residual avg_queries_until_success : [0, 0, 0, 0, 0, 0, 0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 90.05 %
Accuracy attacked model: 90.05
Testing: white-box
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-backward
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: two-point-central
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Testing: one-point-residual
Accuracy: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Variance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

Accuracy attacked model: 90.05
Defense model: net3conv
Dataset: f-mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual variance : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-central avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 0, H_0 rejected: True
one-point-residual, two-point-forward z_test: 0, H_0 rejected: True
one-point-residual, two-point-backward z_test: 0, H_0 rejected: True
one-point-residual, two-point-central z_test: 0, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0, H_0 rejected: True
Testing pgd attack with estimates
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0], eps_iters: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3], nb_iter: 100
Loading 'defense' is done.
Accuracy of netV: 99.55 %
Accuracy attacked model: 99.55
Testing: white-box
Accuracy: [0.01, 0.054, 0.203, 0.566, 0.864, 0.967, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.051, 0.162, 0.246, 0.118, 0.032, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Testing: two-point-forward
Accuracy: [0.01, 0.039, 0.095, 0.303, 0.617, 0.839, 0.938, 0.982, 0.999, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.038, 0.087, 0.212, 0.237, 0.135, 0.058, 0.018, 0.001, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [3009.753, 2475.323, 2026.38, 1649.713, 1360.783, 1131.043, 950.573]

Testing: two-point-backward
Accuracy: [0.01, 0.038, 0.096, 0.299, 0.619, 0.847, 0.939, 0.985, 0.998, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.037, 0.087, 0.21, 0.237, 0.13, 0.057, 0.015, 0.002, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [3025.787, 2484.313, 2004.31, 1645.907, 1364.217, 1126.827, 950.4]

Testing: two-point-central
Accuracy: [0.01, 0.039, 0.098, 0.324, 0.639, 0.864, 0.946, 0.991, 0.999, 1.0, 1.0, 1.0, 1.0]
Variance: [0.01, 0.038, 0.089, 0.22, 0.232, 0.118, 0.051, 0.009, 0.001, 0.0, 0.0, 0.0, 0.0]
Average number of queries until succes: [5673.73, 4691.443, 3761.463, 3065.267, 2509.733, 2106.467, 1761.0]

Testing: one-point-residual
Accuracy: [0.01, 0.031, 0.079, 0.205, 0.44, 0.723, 0.88, 0.955, 0.991, 0.999, 1.0, 1.0, 1.0]
Variance: [0.01, 0.03, 0.073, 0.163, 0.247, 0.201, 0.106, 0.043, 0.009, 0.001, 0.0, 0.0, 0.0]
Average number of queries until succes: [3681.363, 3135.13, 2630.323, 2163.07, 1780.8, 1487.2, 1227.967]

Accuracy attacked model: 99.55
Defense model: net3conv
Dataset: mnist
Attack_name: L2-PGD
epsilons: [0.05, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0]
eps_iter: [0.0025, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]
nb_iter: 100
nb_samples: 50
fd_eta: 1.5
All results: 
Type white-box accuracy : [0.01, 0.054, 0.203, 0.566, 0.864, 0.967, 0.998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Type white-box variance : [0.01, 0.051, 0.162, 0.246, 0.118, 0.032, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward accuracy : [0.01, 0.039, 0.095, 0.303, 0.617, 0.839, 0.938, 0.982, 0.999, 1.0, 1.0, 1.0, 1.0]
Type two-point-forward variance : [0.01, 0.038, 0.087, 0.212, 0.237, 0.135, 0.058, 0.018, 0.001, 0.0, 0.0, 0.0, 0.0]
Type two-point-backward accuracy : [0.01, 0.038, 0.096, 0.299, 0.619, 0.847, 0.939, 0.985, 0.998, 1.0, 1.0, 1.0, 1.0]
Type two-point-backward variance : [0.01, 0.037, 0.087, 0.21, 0.237, 0.13, 0.057, 0.015, 0.002, 0.0, 0.0, 0.0, 0.0]
Type two-point-central accuracy : [0.01, 0.039, 0.098, 0.324, 0.639, 0.864, 0.946, 0.991, 0.999, 1.0, 1.0, 1.0, 1.0]
Type two-point-central variance : [0.01, 0.038, 0.089, 0.22, 0.232, 0.118, 0.051, 0.009, 0.001, 0.0, 0.0, 0.0, 0.0]
Type one-point-residual accuracy : [0.01, 0.031, 0.079, 0.205, 0.44, 0.723, 0.88, 0.955, 0.991, 0.999, 1.0, 1.0, 1.0]
Type one-point-residual variance : [0.01, 0.03, 0.073, 0.163, 0.247, 0.201, 0.106, 0.043, 0.009, 0.001, 0.0, 0.0, 0.0]
Type white-box avg_queries_until_success : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Type two-point-forward avg_queries_until_success : [3009.753, 2475.323, 2026.38, 1649.713, 1360.783, 1131.043, 950.573]
Type two-point-backward avg_queries_until_success : [3025.787, 2484.313, 2004.31, 1645.907, 1364.217, 1126.827, 950.4]
Type two-point-central avg_queries_until_success : [5673.73, 4691.443, 3761.463, 3065.267, 2509.733, 2106.467, 1761.0]
Type one-point-residual avg_queries_until_success : [3681.363, 3135.13, 2630.323, 2163.07, 1780.8, 1487.2, 1227.967]
test z at epsilon: 2.5
one-point-residual, white-box z_test: 11.323, H_0 rejected: True
one-point-residual, two-point-forward z_test: 4.479, H_0 rejected: True
one-point-residual, two-point-backward z_test: 4.828, H_0 rejected: True
one-point-residual, two-point-central z_test: 5.593, H_0 rejected: True
one-point-residual, one-point-residual z_test: 0.0, H_0 rejected: False
